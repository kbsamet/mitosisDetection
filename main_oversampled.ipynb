{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def focal_loss(gamma=2., alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "        y_true = K.cast(y_true, tf.float32)\n",
    "        alpha_t = y_true * alpha + (K.ones_like(y_true) - y_true) * (1 - alpha)\n",
    "        p_t = y_true * y_pred + (K.ones_like(y_true) - y_true) * (1 - y_pred)\n",
    "        fl = - alpha_t * K.pow((K.ones_like(y_true) - p_t), gamma) * K.log(p_t)\n",
    "        return K.mean(fl)\n",
    "    return focal_loss_fixed\n",
    "\n",
    "def load_images_and_masks(data_dir):\n",
    "    images = []\n",
    "    masks = []\n",
    "    \n",
    "    for patient_folder in os.listdir(data_dir):\n",
    "        if not os.path.isdir(os.path.join(data_dir, patient_folder)):\n",
    "            continue\n",
    "        patient_path = os.path.join(data_dir, patient_folder)\n",
    "        \n",
    "        for file in os.listdir(patient_path):\n",
    "            if file.endswith('.bmp'):\n",
    "                # Load image\n",
    "               \n",
    "                image_path = os.path.join(patient_path, file)\n",
    "                image = cv2.imread(image_path)\n",
    "                images.append(image)\n",
    "                \n",
    "                # Create corresponding mask\n",
    "                mask = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
    "                csv_file = file.replace('.bmp', '.csv')\n",
    "                csv_path = os.path.join(patient_path, csv_file)\n",
    "                \n",
    "                if os.path.exists(csv_path):\n",
    "                    try:\n",
    "                        with open(csv_path, 'r') as f:\n",
    "                            lines = f.readlines()\n",
    "                            for line in lines:\n",
    "                                values = line.strip().split(',')\n",
    "                                # Ensure even number of values (pairs of coordinates)\n",
    "                                if len(values) % 2 != 0:\n",
    "                                    print(f\"Warning: Skipping invalid row in {csv_path}: {line}\")\n",
    "                                    continue\n",
    "                                # Convert pairs of coordinates to integers and set mask\n",
    "                                for i in range(0, len(values), 2):\n",
    "                                    try:\n",
    "                                        col_idx = int(values[i])\n",
    "                                        row_idx = int(values[i+1])\n",
    "                                        mask[row_idx, col_idx] = 1\n",
    "                                    except ValueError:\n",
    "                                        print(f\"Warning: Skipping invalid coordinate pair in {csv_path}: ({values[i]}, {values[i+1]})\")\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading {csv_path}: {e}\")\n",
    "                \n",
    "                masks.append(mask)\n",
    "    \n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "def extract_patches(image, patch_size=64, stride=32):\n",
    "    patches = []\n",
    "    coordinates = []\n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    for y in range(0, h - patch_size + 1, stride):\n",
    "        for x in range(0, w - patch_size + 1, stride):\n",
    "            patch = image[y:y + patch_size, x:x + patch_size]\n",
    "            patches.append(patch)\n",
    "            coordinates.append((y, x))\n",
    "    return np.array(patches), coordinates\n",
    "\n",
    "\n",
    "\n",
    "def reconstruct_mask(pred_patches, coordinates, image_shape, patch_size=64, stride=32):\n",
    "    mask = np.zeros((image_shape[0], image_shape[1]))\n",
    "    count = np.zeros((image_shape[0], image_shape[1]))\n",
    "\n",
    "    for i, (y, x) in enumerate(coordinates):\n",
    "        mask[y:y + patch_size, x:x + patch_size] += pred_patches[i].squeeze()\n",
    "        count[y:y + patch_size, x:x + patch_size] += 1\n",
    "    \n",
    "    mask = np.divide(mask, count, out=np.zeros_like(mask), where=count!=0)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_augmented_generators(images, masks, batch_size=32):\n",
    "    data_gen_args = dict(\n",
    "        rotation_range=90,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        brightness_range=[0.8, 1.2]\n",
    "    )\n",
    "\n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    \n",
    "    seed = 1\n",
    "    image_datagen.fit(images, augment=True, seed=seed)\n",
    "    mask_datagen.fit(masks, augment=True, seed=seed)\n",
    "    \n",
    "    image_generator = image_datagen.flow(images, batch_size=batch_size, seed=seed)\n",
    "    mask_generator = mask_datagen.flow(masks, batch_size=batch_size, seed=seed)\n",
    "    \n",
    "    return image_generator, mask_generator\n",
    "\n",
    "\n",
    "def oversample_mitosis_patches_generator(images, masks, patch_size=32, stride=16, oversample_factor=10):\n",
    "    while True:\n",
    "        for image, mask in zip(images, masks):\n",
    "            coords = np.argwhere(mask == 1)\n",
    "            for _ in range(oversample_factor):\n",
    "                for y, x in coords:\n",
    "                    y_min, y_max = max(0, y-patch_size//2), min(image.shape[0], y+patch_size//2)\n",
    "                    x_min, x_max = max(0, x-patch_size//2), min(image.shape[1], x+patch_size//2)\n",
    "                    patch = image[y_min:y_max, x_min:x_max]\n",
    "                    patch_mask = mask[y_min:y_max, x_min:x_max]\n",
    "                    \n",
    "                    if patch.shape[0] == patch_size and patch.shape[1] == patch_size:\n",
    "                        yield patch, patch_mask\n",
    "\n",
    "\n",
    "def patch_generator(images, masks, patch_size=64, stride=16, batch_size=64):\n",
    "    while True:\n",
    "        batch_images = []\n",
    "        batch_masks = []\n",
    "        for image, mask in zip(images, masks):\n",
    "            for y in range(0, image.shape[0] - patch_size + 1, stride):\n",
    "                for x in range(0, image.shape[1] - patch_size + 1, stride):\n",
    "                    image_patch = image[y:y + patch_size, x:x + patch_size]\n",
    "                    mask_patch = mask[y:y + patch_size, x:x + patch_size]\n",
    "                    batch_images.append(image_patch)\n",
    "                    batch_masks.append(mask_patch)\n",
    "                    if len(batch_images) == batch_size:\n",
    "                        yield np.array(batch_images), np.expand_dims(np.array(batch_masks), axis=-1)\n",
    "                        batch_images, batch_masks = [], []\n",
    "        if batch_images:\n",
    "            yield np.array(batch_images), np.expand_dims(np.array(batch_masks), axis=-1)\n",
    "\n",
    "def balanced_patch_generator(images, masks, patch_size=32, stride=16, batch_size=32, oversample_factor=10):\n",
    "    mitosis_generator = oversample_mitosis_patches_generator(images, masks, patch_size, stride, oversample_factor)\n",
    "    \n",
    "    while True:\n",
    "        batch_images = []\n",
    "        batch_masks = []\n",
    "        \n",
    "        non_mitosis_patches = []\n",
    "        non_mitosis_coords = []\n",
    "        \n",
    "        for image, mask in zip(images, masks):\n",
    "            coords = np.argwhere(mask == 0)\n",
    "            for y, x in coords[::stride]:\n",
    "                y_min, y_max = max(0, y-patch_size//2), min(image.shape[0], y+patch_size//2)\n",
    "                x_min, x_max = max(0, x-patch_size//2), min(image.shape[1], x+patch_size//2)\n",
    "                patch = image[y_min:y_max, x_min:x_max]\n",
    "                patch_mask = mask[y_min:y_max, x_min:x_max]\n",
    "                \n",
    "                if patch.shape[0] == patch_size and patch.shape[1] == patch_size:\n",
    "                    non_mitosis_patches.append(patch)\n",
    "                    non_mitosis_coords.append(patch_mask)\n",
    "        \n",
    "        while len(batch_images) < batch_size:\n",
    "            try:\n",
    "                if len(non_mitosis_patches) > 0:\n",
    "                    mitosis_patch, mitosis_mask = next(mitosis_generator)\n",
    "                    batch_images.append(mitosis_patch)\n",
    "                    batch_masks.append(mitosis_mask)\n",
    "                    batch_images.append(non_mitosis_patches.pop())\n",
    "                    batch_masks.append(non_mitosis_coords.pop())\n",
    "                else:\n",
    "                    break\n",
    "            except StopIteration:\n",
    "                break\n",
    "        \n",
    "        if len(batch_images) > 0:\n",
    "            batch_images = np.array(batch_images)\n",
    "            batch_masks = np.expand_dims(np.array(batch_masks), axis=-1)\n",
    "\n",
    "            # Apply augmentations\n",
    "            image_generator, mask_generator = create_augmented_generators(batch_images, batch_masks, batch_size=batch_size)\n",
    "            augmented_images = next(image_generator)\n",
    "            augmented_masks = next(mask_generator)\n",
    "            \n",
    "            yield augmented_images, augmented_masks\n",
    "\n",
    "\n",
    "def generator_to_dataset(generator, output_shape, batch_size):\n",
    "    def gen():\n",
    "        for batch in generator:\n",
    "            yield batch\n",
    "            \n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(batch_size, *output_shape), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(batch_size, *output_shape, 1), dtype=tf.float32)\n",
    "        )\n",
    "    )\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def cross_validation(images, masks, n_splits=5, patch_size=32, stride=16, batch_size=32, oversample_factor=10):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "\n",
    "    for train_index, val_index in kf.split(images):\n",
    "        X_train, X_val = images[train_index], images[val_index]\n",
    "        y_train, y_val = masks[train_index], masks[val_index]\n",
    "\n",
    "        train_generator = balanced_patch_generator(X_train, y_train, patch_size, stride, batch_size, oversample_factor)\n",
    "        val_generator = balanced_patch_generator(X_val, y_val, patch_size, stride, batch_size, oversample_factor)\n",
    "        \n",
    "        num_train_patches = sum(\n",
    "            (image.shape[0] - patch_size + 1) * (image.shape[1] - patch_size + 1) // (stride * stride)\n",
    "            for image in X_train\n",
    "        )\n",
    "        num_val_patches = sum(\n",
    "            (image.shape[0] - patch_size + 1) * (image.shape[1] - patch_size + 1) // (stride * stride)\n",
    "            for image in X_val\n",
    "        )\n",
    "\n",
    "        fold_results.append((train_generator, val_generator, num_train_patches // batch_size, num_val_patches // batch_size, X_val, y_val))\n",
    "    \n",
    "    return fold_results\n",
    "\n",
    "def unet_model(input_size=(64, 64, 3)):\n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    # Encoder\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, 3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, 3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, 3, activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, 3, activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, 3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "    # Decoder\n",
    "    up6 = UpSampling2D(size=(2, 2))(conv5)\n",
    "    up6 = Concatenate()([up6, conv4])\n",
    "    conv6 = Conv2D(256, 3, activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, 3, activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = UpSampling2D(size=(2, 2))(conv6)\n",
    "    up7 = Concatenate()([up7, conv3])\n",
    "    conv7 = Conv2D(128, 3, activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, 3, activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = UpSampling2D(size=(2, 2))(conv7)\n",
    "    up8 = Concatenate()([up8, conv2])\n",
    "    conv8 = Conv2D(64, 3, activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, 3, activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = UpSampling2D(size=(2, 2))(conv8)\n",
    "    up9 = Concatenate()([up9, conv1])\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, 3, activation='relu', padding='same')(conv9)\n",
    "\n",
    "    outputs = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss=focal_loss(), metrics=['accuracy', 'Precision', 'Recall'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    # Flatten the arrays to calculate the metrics at the pixel level\n",
    "    y_true = y_true.flatten()\n",
    "    y_pred = y_pred.flatten()\n",
    "    \n",
    "    # Check for shape consistency\n",
    "    if len(y_true) != len(y_pred):\n",
    "        raise ValueError(f\"Inconsistent number of samples: {len(y_true)} != {len(y_pred)}\")\n",
    "    \n",
    "    # Calculate precision, recall, and F1-score\n",
    "    precision = precision_score(y_true, y_pred, average='binary')\n",
    "    recall = recall_score(y_true, y_pred, average='binary')\n",
    "    f1 = f1_score(y_true, y_pred, average='binary')\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'scanner_A'  # Your data directory\n",
    "input_size = (64, 64, 3)  # Define the input size for the model\n",
    "\n",
    "# Load images and masks\n",
    "images, masks = load_images_and_masks(data_dir)\n",
    "print(f\"Loaded {len(images)} images and {len(masks)} masks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.set_visible_devices([], 'GPU')\n",
    "print(f\"TensorFlow has access to the following devices:\\n{tf.config.list_physical_devices()}\")\n",
    "# Check class distribution\n",
    "total_pixels = np.prod(masks.shape)\n",
    "num_mitosis_pixels = np.sum(masks)\n",
    "num_non_mitosis_pixels = total_pixels - num_mitosis_pixels\n",
    "print(f\"Mitosis pixels: {num_mitosis_pixels}, Non-mitosis pixels: {num_non_mitosis_pixels}\")\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "fold_results = cross_validation(images, masks , patch_size=64, stride=32, batch_size=256,oversample_factor=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold_num, (train_gen, val_gen, train_steps, val_steps, X_val, y_val) in enumerate(fold_results):\n",
    "    print(f\"Fold {fold_num + 1}\")\n",
    "\n",
    "    # Define and compile the model\n",
    "    model = unet_model(input_size=input_size)\n",
    "    # Train the model using the training generator and validate it on the validation data\n",
    "    model.fit(train_gen,\n",
    "                validation_data=val_gen,\n",
    "                epochs=1,  # Adjust the number of epochs as needed\n",
    "                steps_per_epoch=train_steps,\n",
    "                validation_steps=val_steps, \n",
    "                verbose=1)\n",
    "    \n",
    "    print(f\"Model trained on fold {fold_num + 1}\")\n",
    "    model.save('model.keras')\n",
    "\n",
    "    # Reconstruct the full validation mask\n",
    "    patches, coords = extract_patches(X_val[0], patch_size=64, stride=32)\n",
    "    val_patch_preds = model.predict(patches)\n",
    "    val_patch_preds = np.nan_to_num(val_patch_preds, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "    val_patch_preds = (val_patch_preds > 0.5).astype(np.uint8)  # Convert predictions to binary masks\n",
    "    val_mask_pred = reconstruct_mask(val_patch_preds, coords, X_val[0].shape, patch_size=64, stride=32)\n",
    "    \n",
    "    precision, recall, f1 = calculate_metrics(y_val.flatten(), val_mask_pred.flatten())\n",
    "    print(f\"Fold {fold_num + 1} - Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.models.load_model('model.keras', custom_objects={'focal_loss_fixed': focal_loss()})\n",
    "for fold_num, (train_gen, val_gen, train_steps, val_steps, X_val, y_val) in enumerate(fold_results):\n",
    "    next(train_gen)\n",
    "    next(train_gen)\n",
    "    image, mask = next(train_gen)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.subplot(221)\n",
    "    plt.imshow(image[0])\n",
    "    plt.title('Image')\n",
    "    plt.subplot(222)\n",
    "    plt.imshow(mask[0].squeeze(), cmap='gray')\n",
    "    plt.title('Mask')\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model.keras', custom_objects={'focal_loss_fixed': focal_loss()})\n",
    "image = images[0]\n",
    "mask = masks[0].squeeze()\n",
    "patch_size = 64\n",
    "stride = 32\n",
    "patches, coords = extract_patches(image, patch_size=patch_size, stride=stride)\n",
    "patch_preds = model.predict(patches)\n",
    "patch_preds = np.nan_to_num(patch_preds, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "patch_preds = (patch_preds > 0.5).astype(np.uint8)\n",
    "mask_pred = reconstruct_mask(patch_preds, coords, image.shape, patch_size=patch_size, stride=stride)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(221)\n",
    "plt.imshow(image)\n",
    "plt.title('Image')\n",
    "plt.subplot(222)\n",
    "plt.imshow(mask, cmap='gray')\n",
    "plt.title('Mask')\n",
    "plt.subplot(223)\n",
    "plt.imshow(mask_pred, cmap='gray')\n",
    "plt.title('Predicted Mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training and evaluation completed.\")\n",
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
